<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT" />










<meta property="og:type" content="website">
<meta property="og:title" content="漫卷云舒">
<meta property="og:url" content="https://maoyunyao.github.io/index.html">
<meta property="og:site_name" content="漫卷云舒">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="漫卷云舒">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://maoyunyao.github.io/"/>





  <title>漫卷云舒</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>
  <!--Fork me on github-->
  <a href="https://github.com/maoyunyao" class="github-corner" aria-label="View source on Github"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
  <!--Fork me on github-->
	<header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">漫卷云舒</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">蜗壳的里的时光</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://maoyunyao.github.io/2019/08/04/algorithm_hungarian/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.M">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="漫卷云舒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/04/algorithm_hungarian/" itemprop="url">Hungarian Algorithm</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-04T12:00:00+10:00">
                2019-08-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/算法/" itemprop="url" rel="index">
                    <span itemprop="name">算法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Hungarian-Algorithm"><a href="#Hungarian-Algorithm" class="headerlink" title="Hungarian Algorithm"></a>Hungarian Algorithm</h2><h4 id="Brief-introduction"><a href="#Brief-introduction" class="headerlink" title="Brief introduction:"></a>Brief introduction:</h4><p>A combinatorial optimization algorithm that solves the assignment problem in polynomial time.</p>
<p>It was developed and published in 1955 by <a href="https://en.wikipedia.org/wiki/Harold_Kuhn" target="_blank" rel="noopener">Harold Kuhn</a>, who gave the name “Hungarian method” because the algorithm was largely based on the earlier works of two <a href="https://en.wikipedia.org/wiki/Hungary" target="_blank" rel="noopener">Hungarian</a> mathematicians: <a href="https://en.wikipedia.org/wiki/D%C3%A9nes_K%C5%91nig" target="_blank" rel="noopener">Dénes Kőnig</a> and <a href="https://en.wikipedia.org/wiki/Jen%C5%91_Egerv%C3%A1ry" target="_blank" rel="noopener">Jenő Egerváry</a>.</p>
<p>There are two ways to formulate the problem: as a matrix or as a bipartite graph.</p>
<h4 id="Matrix-Formulation"><a href="#Matrix-Formulation" class="headerlink" title="Matrix Formulation:"></a>Matrix Formulation:</h4><p>In the matrix formulation, we are given a nonnegative <em>n×n</em> matrix, where the element in the <em>i</em>-th row and <em>j</em>-th column represents the cost of assigning the <em>j</em>-th job to the <em>i</em>-th worker. We have to find an assignment of the jobs to the workers, such that each job is assigned to one worker and each worker is assigned one job, such that the total cost of assignment is minimum.</p>
<h4 id="Bigraph-Formulation"><a href="#Bigraph-Formulation" class="headerlink" title="Bigraph Formulation:"></a>Bigraph Formulation:</h4><p>In the matrix formulation, we have a complete bipartite graph $G=(S,T;E)​$ with <em>n</em> worker vertices ($S​$) and <em>n</em> job vertices ($T​$), and each edge has a nonnegative cost $c(i,j)​$. We want to find a perfect matching with a minimum total cost.</p>
<h4 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm:"></a>Algorithm:</h4><p>Here we describe the algorithm in terms of matrix graphs.</p>
<p><strong>Theorem:</strong> If a number is added to or subtracted from all of the entries of any one row or column of a cost matrix, then on optimal assignment for the resulting cost matrix is also an optimal assignment for the original cost matrix.</p>
<p>The following algorithm applies the above theorem to a given n × n cost matrix to find an optimal assignment:</p>
<p><strong>Step 1.</strong> Subtract the smallest entry in each row from all the entries of its row.</p>
<p><strong>Step 2.</strong> Subtract the smallest entry in each column from all the entries of its column.</p>
<p><strong>Step 3.</strong> Draw lines through appropriate rows and columns so that all the zero entries of the cost matrix are covered and the minimum number of such lines is used.</p>
<p><strong>Step 4.</strong> Test for Optimality:</p>
<ul>
<li>If the minimum number of covering lines is n, an optimal assignment of zeros is possible and we are finished.</li>
<li>If the minimum number of covering lines is less than n, an optimal assignment of zeros is not yet possible. In that case, proceed to <strong>Step 5.</strong></li>
</ul>
<p><strong>Step 5.</strong> Determine the smallest entry not covered by any line. Subtract this entry from each uncovered row, and then add it to each covered column. Return to <strong>Step 3.</strong></p>
<h4 id="An-example"><a href="#An-example" class="headerlink" title="An example:"></a>An example:</h4><p><strong>Problem:</strong></p>
<script type="math/tex; mode=display">
\left[
 \begin{matrix}
   90 & 75 & 75 & 80\\
   35 & 85 & 55 & 65 \\
   125 & 95 & 90 & 105 \\
   45 & 110 & 95 & 115
  \end{matrix}
  \right]</script><p><strong>Step 1:</strong> Subtract 75 from Row 1, 35 from Row 2, 90 from Row 3, and 45 from Row 4.</p>
<script type="math/tex; mode=display">
\left[
 \begin{matrix}
   90 & 75 & 75 & 80\\
   35 & 85 & 55 & 65 \\
   125 & 95 & 90 & 105 \\
   45 & 110 & 95 & 115
  \end{matrix}
  \right]
  \to
\left[
 \begin{matrix}
    15 & 0 & 0 & 5 \\
    0 & 50 & 20 & 30 \\
    35 & 5 & 0 & 15 \\
    0 & 65 & 50 & 70 \\
  \end{matrix}
  \right]</script><p><strong>Step 2:</strong> Subtract 0 from Column 1, 0 from Column 2, 0 from Column 3, and 5 from Column 4.</p>
<script type="math/tex; mode=display">
\left[
 \begin{matrix}
    15 & 0 & 0 & 5 \\
    0 & 50 & 20 & 30 \\
    35 & 5 & 0 & 15 \\
    0 & 65 & 50 & 70 \\
  \end{matrix}
  \right]
  \to
  \left[
 \begin{matrix}
    15 & 0 & 0 & 0 \\
    0 & 50 & 20 & 25 \\
    35 & 5 & 0 & 10 \\
    0 & 65 & 50 & 65 \\
  \end{matrix}
  \right]</script><p><strong>Step 3:</strong> Cover all the zeros of the matrix with the minimum number of horizontal or vertical lines.</p>
<script type="math/tex; mode=display">
\left[
 \begin{matrix}
    15 & 0 & 0 & 0 \\
    0 & 50 & 20 & 25 \\
    35 & 5 & 0 & 10 \\
    0 & 65 & 50 & 65 \\
  \end{matrix}
  \right]
  \to
  \left[
 \begin{matrix}
    \color{red}{15} & \color{red}0 & \color{red}0 & \color{red}0 \\
    \color{red}0 & 50 & \color{red}{20} & 25 \\
    \color{red}{35} & 5 & \color{red}0 & 10 \\
    \color{red}0 & 65 & \color{red}{50} & 65 \\
  \end{matrix}
  \right]</script><p><strong>Step 4:</strong> Since the minimal number of lines is less than 4, we have to proceed to Step 5.</p>
<p><strong>Step 5:</strong> Note that 5 is the smallest entry not covered by any line. Subtract 5 from each uncovered row.</p>
<script type="math/tex; mode=display">
\left[
 \begin{matrix}
    15 & 0 & 0 & 0 \\
    0 & 50 & 20 & 25 \\
    35 & 5 & 0 & 10 \\
    0 & 65 & 50 & 65 \\
  \end{matrix}
  \right]
  \to
\left[
 \begin{matrix}
    15 & 0 & 0 & 0 \\
    -5 & 45 & 15 & 20 \\
    30 & 0 & -5 & 5 \\
    -5 & 60 & 45 & 60 \\
  \end{matrix}
  \right]</script><p>Now add 5 to each covered column:</p>
<script type="math/tex; mode=display">
\left[
 \begin{matrix}
    15 & 0 & 0 & 0 \\
    -5 & 45 & 15 & 20 \\
    30 & 0 & -5 & 5 \\
    -5 & 60 & 45 & 60 \\
  \end{matrix}
  \right]
  \to
\left[
 \begin{matrix}
    20 & 0 & 5 & 0 \\
    0 & 45 & 20 & 20 \\
    35 & 0 & 0 & 5 \\
    0 & 60 & 50 & 60 \\
  \end{matrix}
  \right]</script><p>Now return to Step 3.</p>
<p><strong>Step 3:</strong> Cover all the zeros of the matrix with the minimum number of horizontal or vertical lines.</p>
<script type="math/tex; mode=display">
\left[
 \begin{matrix}
    20 & 0 & 5 & 0 \\
    0 & 45 & 20 & 20 \\
    35 & 0 & 0 & 5 \\
    0 & 60 & 50 & 60 \\
  \end{matrix}
  \right]
  \to
  \left[
 \begin{matrix}
    \color{red}{20} & \color{red}0 & \color{red}5 & \color{red}0 \\
    \color{red}0 & 45 & 20 & 20 \\
    \color{red}{35} & \color{red}0 & \color{red}0 & \color{red}5 \\
    \color{red}0 & 60 & 50 & 60 \\
  \end{matrix}
  \right]</script><p><strong>Step 4:</strong> Since the minimal number of lines is still less than 4, we have to return to Step 5.</p>
<p><strong>Step 5:</strong> Note that 20 is the smallest entry not covered by a line. Subtract 20 from each uncovered row.</p>
<script type="math/tex; mode=display">
\left[
 \begin{matrix}
    20 & 0 & 5 & 0 \\
    0 & 45 & 20 & 20 \\
    35 & 0 & 0 & 5 \\
    0 & 60 & 50 & 60 \\
  \end{matrix}
  \right]
  \to
  \left[
 \begin{matrix}
    20 & 0 & 5 & 0 \\
    -20 & 25 & 0 & 0 \\
    35 & 0 & 0 & 5 \\
    -20 & 40 & 30 & 40 \\
  \end{matrix}
  \right]</script><p>Then add 20 to each covered column.</p>
<script type="math/tex; mode=display">
\left[
 \begin{matrix}
    20 & 0 & 5 & 0 \\
    -20 & 25 & 0 & 0 \\
    35 & 0 & 0 & 5 \\
    -20 & 40 & 30 & 40 \\
  \end{matrix}
  \right]
  \to
    \left[
 \begin{matrix}
    40 & 0 & 5 & 0 \\
    0 & 25 & 0 & 0 \\
    55 & 0 & 0 & 5 \\
    0 & 40 & 30 & 40 \\
  \end{matrix}
  \right]</script><p>Now return to Step 3.</p>
<p><strong>Step 3:</strong> Cover all the zeros of the matrix with the minimum number of horizontal or vertical lines.</p>
<script type="math/tex; mode=display">
\left[
 \begin{matrix}
    \color{red}{40} & \color{red}0 & \color{red}5 & \color{red}0 \\
    \color{red}0 & \color{red}{25} & \color{red}0 & \color{red}0 \\
    \color{red}{55} & \color{red}0 & \color{red}0 & \color{red}5 \\
    \color{red}0 & \color{red}{40} & \color{red}{30} & \color{red}{40} \\
  \end{matrix}
  \right]</script><p><strong>Step 4:</strong> Since the minimal number of lines is 4, an optimal assignment of zeros is possible and we are finished.</p>
<script type="math/tex; mode=display">
\left[
 \begin{matrix}
    40 & 0 & 5 & \boxed0 \\
    0 & 25 & \boxed0 & 0 \\
    55 & \boxed0 & 0 & 5 \\
    \boxed0 & 40 & 30 & 40 \\
  \end{matrix}
  \right]</script><p>Since the total cost for this assignment is 0, it must be an optimal assignment.</p>
<p>Here is the same assignment made to the original cost matrix.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Hungarian algorithm, Wikipedia</p>
<p>[2] The Assignment Problem and the Hungarian Method, Bruff, Derek,</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://maoyunyao.github.io/2019/07/03/algorithm_ransac/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.M">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="漫卷云舒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/03/algorithm_ransac/" itemprop="url">RANSAC</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-03T12:00:00+10:00">
                2019-07-03
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/算法/" itemprop="url" rel="index">
                    <span itemprop="name">算法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Random-sample-consensus"><a href="#Random-sample-consensus" class="headerlink" title="Random sample consensus"></a>Random sample consensus</h2><h4 id="Brief-introduction"><a href="#Brief-introduction" class="headerlink" title="Brief introduction:"></a>Brief introduction:</h4><p>An iterative method to estimate parameters of a mathematical model from a set of observed data that contains outliers, when outliers are to be accorded no influence on the values of the estimates.</p>
<p>The algorithm was first published by Fischler and Bolles at SRI International in 1981. They used RANSAC to solve the Location Determination Problem (LDP), where the goal is to determine the points in the space that project onto an image into a set of landmarks with known locations.</p>
<h4 id="Algorithm"><a href="#Algorithm" class="headerlink" title="Algorithm:"></a>Algorithm:</h4><p>The RANSAC algorithm is essentially composed of two steps that are iteratively repeated:</p>
<ol>
<li>In the first step, a sample subset containing minimal data items is randomly selected from the input dataset. A fitting model and the corresponding model parameters are computed using only the elements of this sample subset. <strong>The cardinality of the sample subset is the smallest sufficient to determine the model parameters</strong>.</li>
<li>In the second step, the algorithm checks which elements of the entire dataset are consistent with the model instantiated by the estimated model parameters obtained from the first step. A data element will be considered as an outlier if it does not fit the fitting model instantiated by the set of estimated model parameters within some error threshold that defines the maximum deviation attributable to the effect of noise.</li>
</ol>
<p>The set of inliers obtained for the fitting model is called consensus set. The RANSAC algorithm will iteratively repeat the above two steps until the obtained consensus set in certain iteration has enough inliers.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] RANSAC, Wikipedia</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://maoyunyao.github.io/2019/07/01/3DV_PineholeCameraModel/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.M">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="漫卷云舒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/01/3DV_PineholeCameraModel/" itemprop="url">Pinhole Camera Model</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-01T12:00:00+10:00">
                2019-07-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/三维视觉/" itemprop="url" rel="index">
                    <span itemprop="name">三维视觉</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Pinhole-Camera-Model"><a href="#Pinhole-Camera-Model" class="headerlink" title="Pinhole Camera Model"></a>Pinhole Camera Model</h2><p>The <strong>pinhole camera model</strong> describes the mathematical relationship between the coordinates of a point in three-dimensional space and its projection onto the image plane of an ideal pinhole camera, where the camera aperture is described as a point and no lenses are used to focus light. </p>
<h4 id="Model-analysis"><a href="#Model-analysis" class="headerlink" title="Model analysis"></a>Model analysis</h4><p><img src="/img/PinholeCameraModel/PinholeCameraModel.png" alt=""></p>
<script type="math/tex; mode=display">
\frac{-y_1}{f}=\frac{x_1}{x_3}\\
\frac{-y_2}{f}=\frac{x_2}{x_3}\\</script><p>This can be summarized as:</p>
<script type="math/tex; mode=display">
\left[ \begin{array}{ccc}
y_1\\
y_2
\end{array} 
\right]
= -\frac{f}{x_3}
\left[ \begin{array}{ccc}
x_1\\
x_2
\end{array} 
\right]</script><p>Which is an expression that describes the relation between the 3D coordinates $(x_1,x_2,x_3)$ of point <strong>P</strong> and its image coordinates $(y_1,y_2)$ given by point <strong>Q</strong> in the image plane. </p>
<p>Rotate the coordinate system in the image plane 180°, so the negation is removed:</p>
<script type="math/tex; mode=display">
\left[ \begin{array}{ccc}
y_1\\
y_2
\end{array} 
\right]
= \frac{f}{x_3}
\left[ \begin{array}{ccc}
x_1\\
x_2
\end{array} 
\right]</script><h4 id="Camera-matrix"><a href="#Camera-matrix" class="headerlink" title="Camera matrix"></a>Camera matrix</h4><ul>
<li><strong>Homogeneous coordinates for equation above:</strong><script type="math/tex; mode=display">
\left[ \begin{array}{ccc}
y_1\\
y_2\\
1
\end{array} 
\right]
= \frac{f}{x_3}
\left[ \begin{array}{ccc}
x_1\\
x_2\\
\frac{x_3}{f}
\end{array} 
\right]
= \frac{1}{x_3}
\left[ \begin{array}{ccc}
f & 0 & 0 & 0\\
0 & f & 0 & 0\\
0 & 0 & 1 & 0\\
\end{array} 
\right]
\left[ \begin{array}{ccc}
x_1\\
x_2\\
x_3\\
1
\end{array} 
\right]</script>Matrix $C$ is the camera matrix<script type="math/tex; mode=display">
C
= 
\left[ \begin{array}{ccc}
f & 0 & 0 & 0\\
0 & f & 0 & 0\\
0 & 0 & 1 & 0
\end{array} 
\right]</script></li>
</ul>
<h4 id="Intrinsic-matrix"><a href="#Intrinsic-matrix" class="headerlink" title="Intrinsic matrix"></a>Intrinsic matrix</h4><ul>
<li><p><strong>Image coordinates to pixel coordinates:</strong></p>
<script type="math/tex; mode=display">
u = \frac{x}{dx} + u_0\\
v = \frac{y}{dy} + v_0</script><p>That is:</p>
<script type="math/tex; mode=display">
\left[ \begin{array}{ccc}
u\\
v\\
1
\end{array} 
\right]
=
\left[ \begin{array}{ccc}
\frac{1}{dx} & 0 & u_0\\
0 & \frac{1}{dy} & v_0\\
0 & 0 & 1
\end{array} 
\right]
\left[ \begin{array}{ccc}
x\\
y\\
1
\end{array} 
\right]</script><p>Where dx and dy means the width of the pixel.(1 mm per pixel for example)</p>
</li>
<li><p><strong>Camera 3D coordinates to pixel coordinates:</strong></p>
<script type="math/tex; mode=display">
\left[ \begin{array}{ccc}
y_1\\
y_2\\
1
\end{array} 
\right]
= \frac{1}{x_3}
\left[ \begin{array}{ccc}
\frac{1}{dx} & 0 & u_0\\
0 &\frac{1}{dy} & v_0\\
0 & 0 & 1
\end{array} 
\right]
\left[ \begin{array}{ccc}
f & 0 & 0 & 0\\
0 & f & 0 & 0\\
0 & 0 & 1 & 0\\
\end{array} 
\right]
\left[ \begin{array}{ccc}
x_1\\
x_2\\
x_3\\
1
\end{array} 
\right]</script></li>
<li><p><strong>Combination of the two matrix:</strong></p>
<script type="math/tex; mode=display">
\left[ \begin{array}{ccc}
y_1\\
y_2\\
1
\end{array} 
\right]
= \frac{1}{x_3}
\left[ \begin{array}{ccc}
\frac{f}{dx} & 0 & u_0 & 0\\
0 & \frac{f}{dy} & v_0 & 0\\
0 & 0 & 1 & 0\\
\end{array} 
\right]
\left[ \begin{array}{ccc}
x_1\\
x_2\\
x_3\\
1
\end{array} 
\right]</script><p>Matrix $I$ is the intrinsic matrix</p>
<script type="math/tex; mode=display">
I =
\left[ \begin{array}{ccc}
\frac{f}{dx} & 0 & u_0 & 0\\
0 & \frac{f}{dy} & v_0 & 0\\
0 & 0 & 1 & 0\\
\end{array} 
\right]</script></li>
</ul>
<h4 id="Extrinsic-matrix"><a href="#Extrinsic-matrix" class="headerlink" title="Extrinsic matrix"></a>Extrinsic matrix</h4><p>Which denote the coordinate system <strong>transformations from 3D world coordinates to 3D camera coordinates</strong>.</p>
<p><img src="/img/PinholeCameraModel/world2camera.png" alt=""></p>
<ul>
<li><p><strong>Transformation:</strong></p>
<script type="math/tex; mode=display">
\left[ \begin{array}{ccc}
x_c\\
y_c\\
z_c\\
1
\end{array} 
\right]
=
\left[ \begin{array}{ccc}
\textbf{R} & \textbf{T}\\
\textbf{0}^T & 1\\
\end{array} 
\right]

\left[ \begin{array}{ccc}
x_w\\
y_w\\
z_w\\
1
\end{array} 
\right]</script></li>
<li><p><strong>R matrix:</strong></p>
<p>For a point $p$ in world coordinates, we can represent it as:</p>
<script type="math/tex; mode=display">
p = x_w \cdot \vec{x} +y_w \cdot \vec{y} +z_w \cdot \vec{z}</script><p>Where $\vec{x},\vec{y}$ and $\vec{z}$ are the unit vector of world coordinates. Now we only consider the rotation transformation between the two coordinates. For unit vectors in camera coordinates, we can represent them in world coordinates as:</p>
<script type="math/tex; mode=display">
\vec{u} = r_{11} \cdot \vec{x} + r_{12} \cdot \vec{y} + r_{13} \cdot \vec{z}\\
\vec{v} = r_{21} \cdot \vec{x} + r_{22} \cdot \vec{y} + r_{23} \cdot \vec{z}\\
\vec{w} = r_{31} \cdot \vec{x} + r_{32} \cdot \vec{y} + r_{33} \cdot \vec{z}</script><p>Where $\vec{u},\vec{v}$ and $\vec{w}$ are the unit vector of camera coordinates. And also we can rewrite the equation in matrix:</p>
<script type="math/tex; mode=display">
\left[ \begin{array}{ccc}
\vec{u}\\
\vec{v}\\
\vec{w}
\end{array} 
\right]
=
\left[ \begin{array}{ccc}
r_{11} & r_{12} & r_{13}\\
r_{21} & r_{22} & r_{23}\\
r_{31} & r_{32} & r_{23}\\
\end{array} 
\right]
\left[ \begin{array}{ccc}
\vec{x}\\
\vec{y}\\
\vec{z}
\end{array} 
\right]</script><p>So the point $p$ can be represented in camera coordinates as:</p>
<script type="math/tex; mode=display">
p = x_w \cdot \vec{x} +y_w \cdot \vec{y} +z_w \cdot \vec{z}\\
= 
\left[ \begin{array}{ccc}
x_w & y_w & z_w
\end{array} 
\right]
\left[ \begin{array}{ccc}
\vec{x}\\
\vec{y}\\
\vec{z}
\end{array} 
\right]
=
\left[ \begin{array}{ccc}
x_w & y_w & z_w
\end{array} 
\right]
\left[ \begin{array}{ccc}
r_{11} & r_{12} & r_{13}\\
r_{21} & r_{22} & r_{23}\\
r_{31} & r_{32} & r_{23}\\
\end{array} 
\right]^{-1}
\left[ \begin{array}{ccc}
\vec{u}\\
\vec{v}\\
\vec{w}
\end{array} 
\right]</script><p>And thus the relationship between $x_c, \, y_c, \, z_c$ and $x_w, \, y_w, \, z_w$ is:</p>
<script type="math/tex; mode=display">
p
= 
\left[ \begin{array}{ccc}
x_c & y_c & z_c
\end{array} 
\right]
\left[ \begin{array}{ccc}
\vec{u}\\
\vec{v}\\
\vec{w}
\end{array} 
\right]
=
\left[ \begin{array}{ccc}
x_w & y_w & z_w
\end{array} 
\right]
\left[ \begin{array}{ccc}
r_{11} & r_{12} & r_{13}\\
r_{21} & r_{22} & r_{23}\\
r_{31} & r_{32} & r_{23}\\
\end{array} 
\right]^{-1}
\left[ \begin{array}{ccc}
\vec{u}\\
\vec{v}\\
\vec{w}
\end{array} 
\right]</script><p>We can get the equation as follows:</p>
<script type="math/tex; mode=display">
\left[ \begin{array}{ccc}
x_c\\
y_c\\
z_c
\end{array} 
\right]

=
\Bigg(
\left[ \begin{array}{ccc}
r_{11} & r_{12} & r_{13}\\
r_{21} & r_{22} & r_{23}\\
r_{31} & r_{32} & r_{33}
\end{array} 
\right]^{-1}
\Bigg)^T
\left[ \begin{array}{ccc}
x_w\\
y_w\\
z_w
\end{array} 
\right]</script><p>Here the R matrix is just what we want:</p>
<script type="math/tex; mode=display">
R
=
\Bigg(
\left[ \begin{array}{ccc}
r_{11} & r_{12} & r_{13}\\
r_{21} & r_{22} & r_{23}\\
r_{31} & r_{32} & r_{33}
\end{array} 
\right]^{-1}
\Bigg)^T</script></li>
<li><p><strong>T matrix:</strong></p>
<p>Then we can consider the translation. Of course it’s quite simple compared with the rotation situation.</p>
<p>Assume that the position of the camera hole in the world coordinates is $(t_1, t_2, t_3)$, we have:</p>
<script type="math/tex; mode=display">
\left[ \begin{array}{ccc}
x_c\\
y_c\\
z_c
\end{array} 
\right]

=
\left[ \begin{array}{ccc}
x_w\\
y_w\\
z_w
\end{array} 
\right]
-
\left[ \begin{array}{ccc}
t_1\\
t_2\\
t_3
\end{array} 
\right]</script><p>Here the T matrix is just what we want:</p>
<script type="math/tex; mode=display">
T =
\left[ \begin{array}{ccc}
-t_1\\
-t_2\\
-t_3
\end{array} 
\right]</script></li>
<li><p><strong>Combination of rotation and translation:</strong></p>
<p>In homogeneous coordinates presentation, we can combine these two transformation together as:</p>
<script type="math/tex; mode=display">
\left[ \begin{array}{ccc}
x_c\\
y_c\\
z_c\\
1
\end{array} 
\right]
=
\left[ \begin{array}{ccc}
\textbf{R} & \textbf{T}\\
\textbf{0}^T & 1\\
\end{array} 
\right]

\left[ \begin{array}{ccc}
x_w\\
y_w\\
z_w\\
1
\end{array} 
\right]</script></li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Pinhole camera model, Wikipedia</p>
<p>[2] Camera resectioning, Wikipedia</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://maoyunyao.github.io/2019/06/04/measure_mAP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.M">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="漫卷云舒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/06/04/measure_mAP/" itemprop="url">检测模型评估之mAP</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-06-04T12:00:00+10:00">
                2019-06-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="The-object-detection-problem"><a href="#The-object-detection-problem" class="headerlink" title="The object detection problem"></a>The object detection problem</h2><p>Given an image, find the objects in it, <strong>locate their position</strong> and <strong>classify</strong> them.</p>
<p>Trained on a <strong>fixed set of classes</strong>, so the model would locate and classify only those classes in the image.</p>
<p>The location of the object is generally in the form of <strong>a bounding rectangle</strong>.</p>
<h4 id="Dataset-example"><a href="#Dataset-example" class="headerlink" title="Dataset example:"></a>Dataset example:</h4><ul>
<li>Actual image</li>
</ul>
<p><img src="/img/mAP/example.png" alt=""></p>
<ul>
<li>Notation</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">Class</th>
<th style="text-align:center">X coordinate</th>
<th style="text-align:center">Y coordinate</th>
<th style="text-align:center">Box Width</th>
<th style="text-align:center">Box Height</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Dog</td>
<td style="text-align:center">100</td>
<td style="text-align:center">600</td>
<td style="text-align:center">150</td>
<td style="text-align:center">100</td>
</tr>
<tr>
<td style="text-align:center">Horse</td>
<td style="text-align:center">700</td>
<td style="text-align:center">300</td>
<td style="text-align:center">200</td>
<td style="text-align:center">250</td>
</tr>
<tr>
<td style="text-align:center">Person</td>
<td style="text-align:center">400</td>
<td style="text-align:center">400</td>
<td style="text-align:center">100</td>
<td style="text-align:center">500</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>Bounding box with class(only for visualization)</li>
</ul>
<p><img src="/img/mAP/example_visual.png" alt=""></p>
<h2 id="The-Mean-Average-Precision-aka-the-mAP"><a href="#The-Mean-Average-Precision-aka-the-mAP" class="headerlink" title="The Mean Average Precision aka, the mAP"></a>The Mean Average Precision aka, the mAP</h2><p>Every image in an object detection problem could have <strong>different objects of different classes</strong>. So both the classification and localization of a model need to be evaluated. </p>
<h4 id="IoU"><a href="#IoU" class="headerlink" title="IoU"></a>IoU</h4><p>We first need to know how to judge the correctness of each of those detections. The metric that tells us the correctness of a given bounding box is the <strong>IoU</strong> - <strong>Intersection over Union</strong>. It is a very simple visual quantity.</p>
<p><img src="/img/mAP/iou.png" alt=""></p>
<p>The intersection includes the overlap area(the area colored in Cyan), and the union includes the Orange and Cyan regions both.</p>
<p>The IoU will then be calculated like this</p>
<p><img src="/img/mAP/cal_iou.png" alt=""></p>
<h4 id="Identifying-correct-detections-and-calculating-precision-and-recall"><a href="#Identifying-correct-detections-and-calculating-precision-and-recall" class="headerlink" title="Identifying correct detections and calculating precision and recall"></a>Identifying correct detections and calculating <strong>precision</strong> and <strong>recall</strong></h4><p>For calculating <a href="https://tarangshah.com/blog/2018-01-27/what-is-map-understanding-the-statistic-of-choice-for-comparing-object-detection-models/" target="_blank" rel="noopener">Precision and Recall</a>, as with all machine learning problems, we have to identify <strong>True Positives(TP)</strong>, <strong>False Positives(FP)</strong>, <strong>True Negatives(TN)</strong> and <strong>False Negatives(FN)</strong>.</p>
<p><strong>TP</strong> and <strong>FP</strong> are indentified with IoU and a threshold <strong>in a specific class</strong>.</p>
<p>If IoU &gt; threshold: True Positive(TP).</p>
<p>If IoU &lt; threshold: False positive(FP).</p>
<p>For calculating Recall, we need the count of Negatives. Since every part of the image where we didn’t predict an object is considered a negative, measuring “True” negatives is a bit futile. So we only measure False Negatives(FN) - ie. the objects that our model has missed out.</p>
<script type="math/tex; mode=display">
Precision = \frac{TP}{(TP+FP)}\\
Recall = \frac{TP}{(TP+FN)}</script><h4 id="Calculating-the-Mean-Average-Precision"><a href="#Calculating-the-Mean-Average-Precision" class="headerlink" title="Calculating the Mean Average Precision"></a>Calculating the Mean Average Precision</h4><p>Using the Pascal VOC challenge evaluation metric</p>
<p>The Mean Average Precision is a term which has different definitions. This metric is commonly used in the domains of Information Retrieval and Object Detection. Both these domains have different ways of calculating mAP. We will talk about the Object Detection relevant mAP today.</p>
<p>The Object Detection definition of mAP was first formalized in the PASCAL Visual Objects Classes(VOC) challenge, which included various image processing tasks. For the exact paper refer to <a href="http://homepages.inf.ed.ac.uk/ckiw/postscript/ijcv_voc09.pdf" target="_blank" rel="noopener">this.</a> (<a href="https://tarangshah.com/blog/assets/ijcv_voc09.pdf" target="_blank" rel="noopener">backup</a>)</p>
<p>We use the same approaches for calculation of Precision and Recall as mentioned in the previous section. But, as mentioned, we have at least two other variables which determine the values of Precision and Recall, they are the IOU and the Confidence thresholds.</p>
<p>The IOU is a simple geometric metric, which we can easily standardize, for example the PASCAL VOC challenge evaluates mAP based on 50% IOU, whereas the COCO Challenge goes a step further and evaluates mAP at various threshold ranging from 5% to 95%. The confidence factor on the other hand varies across models, 50% confidence in my model design might probably be equivalent to an 80% confidence in someone else’s model design, which would vary the precision recall curve shape. Hence the PASCAL VOC organizers came up with a way to account for this variation.</p>
<p>We now need a metric to evaluate the models in a model agnostic way.</p>
<p>The paper recommends that we calculate a measure called AP - ie. the Average Precision</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&gt; For a given task and class, the precision/recall curve is</span><br><span class="line">&gt; computed from a method’s ranked output. Recall is defined</span><br><span class="line">&gt; as the proportion of all positive examples ranked above a</span><br><span class="line">&gt; given rank. Precision is the proportion of all examples above</span><br><span class="line">&gt; that rank which are from the positive class. The AP summarises</span><br><span class="line">&gt; the shape of the precision/recall curve, and is de-</span><br><span class="line">&gt; fined as the mean precision at a set of eleven equally spaced</span><br><span class="line">&gt; recall levels [0,0.1,...,1]:</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<script type="math/tex; mode=display">
AP = \frac{1}{11} \sum \limits_{r \in\{0, 0.1, 0.2, ... , 1\}}p_{interp}(r)</script><p>This means that we chose 11 different confidence thresholds(which determine the “rank”). The thresholds should be such that the <strong>Recall at those confidence thresholds is 0, 0.1, 0.2, 0.3, … , 0.9 and 1.0</strong>. The AP is now defined as the <strong>mean of the Precision</strong> values at these chosen 11 Recall values. This results in the mAP being an overall view of the whole precision recall curve.</p>
<p>The paper further gets into detail of calculating the Precision used in the above calculation.</p>
<blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; The precision at each recall level r is interpolated by taking</span><br><span class="line">&gt; the maximum precision measured for a method for which</span><br><span class="line">&gt; the corresponding recall exceeds r:</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<script type="math/tex; mode=display">
p_{interp}(r)= \max \limits_{\tilde r:\tilde r \ge r}p(\tilde r)\\
where\ p(\tilde r)\ is\ the\ measured\ precision\ at\ recall\ \tilde r.</script><p>Basically we use the maximum precision for a given recall value.</p>
<p><strong>The mAP hence is the Mean of all the Average Precision values across all your classes as measured above</strong>.</p>
<p>This is in essence how the Mean Average Precision is calculated for Object Detection evaluation. There might be some variation at times, for example the COCO evaluation is more strict, enforcing various metrics with various IOUs and object sizes(<a href="http://cocodataset.org/#detection-eval" target="_blank" rel="noopener">more details here</a>). If any of you want me to go into details of that, do let me know in the comments.</p>
<p>Some important points to remember when we compare mAP values</p>
<ol>
<li>mAP is always calculated over a dataset.</li>
<li>Although it is not easy to interpret the absolute quantification of the model output, mAP helps us by being a pretty good relative metric. When we calculate this metric over popular public datasets, the metric can be easily used to compare old and new approaches to object detection.</li>
<li>Depending on how the classes are distributed in the training data, the Average Precision values might vary from very high for some classes(which had good training data) to very low(for classes with less/bad data). So your mAP may be moderate, but your model might be really good for certain classes and really bad for certain classes. Hence it is advisable to have a look at individual class Average Precisions while analysing your model results. These values might also serve as an indicator to add more training samples.</li>
</ol>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="https://tarangshah.com/blog/2018-01-27/what-is-map-understanding-the-statistic-of-choice-for-comparing-object-detection-models/" target="_blank" rel="noopener">Measuring Object Detection models - mAP - What is Mean Average Precision?</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://maoyunyao.github.io/2019/05/29/paper_GAN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.M">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="漫卷云舒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/29/paper_GAN/" itemprop="url">Generative Adversarial Nets</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-29T12:00:00+10:00">
                2019-05-29
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文阅读/" itemprop="url" rel="index">
                    <span itemprop="name">论文阅读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="生成对抗网络"><a href="#生成对抗网络" class="headerlink" title="生成对抗网络"></a>生成对抗网络</h4><p>同时训练两个网络, 分别是生成网络 $G​$ 和判别网络 $D​$. 其中 $G​$ 网络用于学习真实数据的分布, 而 $D​$ 网络用于判别输入的样本是来自真实数据还是来自 $G​$ 生成的伪数据.</p>
<h5 id="研究背景"><a href="#研究背景" class="headerlink" title="研究背景:"></a>研究背景:</h5><p>截至作者提出生成对抗网络之前, 深度学习的主要成就集中在判别网络的应用中. 这主要归功于反向传播和 $Dropout$ 算法的成功应用. 但是对于生成网络, 其损失函数的设计成了一个难题. 类似于极大似然估计这种损失函数难以很好地被应用在学习的过程当中.</p>
<h5 id="生成网络"><a href="#生成网络" class="headerlink" title="生成网络:"></a>生成网络:</h5><p>生成网络的任务就是学习一个数据分布 $p_g(\textbf{x})$ 来拟合真实数据的分布 $p_{data}(\textbf{x})$. 生成网络 $G$ 接受分布为 $p_{\textbf{z}}(\textbf{z})$ 的随机噪声 $\textbf{z}$ 作为输入, 则 $G$ 可视为从到噪声空间到数据空间的一个映射 ​$G(\textbf{z};\theta_g): \textbf{z} \to \textbf{x}$. 而函数 ​$G$ 是由多层感知机构成的, 以 ​$\theta_g$ 为参数的可导函数.</p>
<h5 id="判别网络"><a href="#判别网络" class="headerlink" title="判别网络:"></a>判别网络:</h5><p>判别网络与常见的判别式网络类似, 它完成一个二分类任务. 以数据样本作为输入, 然后输出一个标量用于表示输入的样本是来自真实数据的概率. 其形式化为 $D(\textbf{x};\theta_d)$.</p>
<h5 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数:"></a>损失函数:</h5><p>生成对抗网络理论上的损失函数如下:</p>
<script type="math/tex; mode=display">
\min \limits_G \space \max \limits_D \space V(D,G) = E_{\textbf{x} \sim p_{data}(\textbf{x})}[logD(\textbf{x})] + E_{\textbf{z} \sim p_{\textbf{z}}(\textbf{z})}[log(1-D(G(\textbf{z})))]</script><p>其直观解释是在最大化 $D​$ 对数据样本的判别能力的条件下，最小化 $D​$ 对 $G​$ 所生成样本的判别能力. 两个网络就像在进行一场博弈, 逐步提升各自的能力, 直到最后 $G​$ 学到的分布完全拟合真实数据分布, 从而达到一个最优的状态. 这时, $D​$ 的输出始终为 $1/2​$, 即无法对输入样本进行有效的判断. </p>
<h5 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程:"></a>训练过程:</h5><p>GAN 的训练过程是一个生成网络 $G​$ 和判别网络 $D​$ 交替迭代训练的过程, 即在训练 $D​$ 时固定 $G​$ 的参数, 而训练 $G​$ 时固定 $D​$ 的参数, 由此循环往复直到训练结束. 结合损失函数我们可以发现, 在训练 $G​$ 时,由于 $D​$ 被固定, $logD(\textbf{x})​$ 就成为了一个常数, 此时训练的目标就是最小化 $log(1-D(G(\textbf{z})))​$.</p>
<p><img src="/img/GAN/algorithm_of_gan.png" alt=""></p>
<center><i>图1:生成对抗网络的训练算法</i></center>

<p>如上图所示的训练算法, 由训练样本的独立同分布采样假设, 理论损失函数中期望的计算可以简单地用样本的平均值来代替. 此外, 对于训练 $G$ 时所采用的 $log(1-D(G(\textbf{z})))$ 损失函数, 在早期会有梯度不足的问题. 因为早期的生成器 $G$ 的能力很弱, 生成的数据很容易被判别器 $D$ 分辨, 从而可能存在绝大多数的生成数据都被分辨出来而导致损失函数值接近 $0$ 的情况. 这时整个训练就进行地十分缓慢, 因为 $log$ 函数在函数值 $0$ 周围梯度比较小. 故而实际训练可以用最大化 $logD(G(\textbf{z}))$ 来代替原来的最小化 $log(1-D(G(\textbf{z})))​$ 的策略, 或者标签反转也是不错的选择.</p>
<p><img src="/img/GAN/example.png" alt=""></p>
<center><i>图2:一个简单的例子</i></center>



<h5 id="理论阐述"><a href="#理论阐述" class="headerlink" title="理论阐述:"></a>理论阐述:</h5>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://maoyunyao.github.io/2019/05/28/paper_Siam_FCN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.M">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="漫卷云舒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/28/paper_Siam_FCN/" itemprop="url">SiamFCN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-28T12:00:00+10:00">
                2019-05-28
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/论文阅读/" itemprop="url" rel="index">
                    <span itemprop="name">论文阅读</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="利用孪生网络进行相似性学习"><a href="#利用孪生网络进行相似性学习" class="headerlink" title="利用孪生网络进行相似性学习"></a>利用孪生网络进行相似性学习</h4><p>训练一个 Siamese 网络, 利用相似性计算来实现在 <strong>search image</strong> 上定位 <strong>exemplar image</strong>.</p>
<h5 id="训练图片"><a href="#训练图片" class="headerlink" title="训练图片:"></a>训练图片:</h5><p>从被标注的视频(<em>每帧中的目标都被 bounding box 框出</em>)中获取用于训练的图片对,  两张图片的帧间隔小于T. 其中 <strong>search image</strong> 是以目标为中心的大小为 $255 \times 255$ 的图片, 超出原图的区域用合理的RGB值填充, 不对原图进行缩放. 而 <strong>exemplar image</strong> 是以目标为中心的大小为 $127 \times 127$ 的图片. 具体地, 若 bounding box(红色框) 的大小为 (w, h), padding 的大小为 p, 则调整因子 s 由以下约束决定, 个人理解下面的两个 s 是不同的调整因子, 最终得到的是一个正方形框图, 即对 $(w+2p) \times (h+2p)$ 以外而 $127 \times 127$ 以内的部分进行合理颜色填充.</p>
<script type="math/tex; mode=display">
s(w + 2p) * s(h + 2p) = A\\
A = 127^2\\
p = (w + h) / 4\\</script><p><img src="/img/siamFCN/exemplar.png" alt=""></p>
<center><i>图1:训练数据的获取</i></center>



<h5 id="训练标注"><a href="#训练标注" class="headerlink" title="训练标注:"></a>训练标注:</h5><p>由于训练帧的目标都在图片中心, 故而训练帧对应的 <strong>score map</strong>, 具体意义参见网络结构)的值由如下规则给出: 距离 <strong>score map</strong> 中心 R 以内的点为正例, 其他点为反例.(需考虑 stride 值, 其中 stride 值为 <strong>search image</strong> 中选出 <strong>candidate image</strong> 时的步长, 由 φ 网络中的池化层决定). 其中 u 为 <strong>score map</strong> D中的点, c 为 <strong>score map</strong> 的中心点, k为 stride 值.</p>
<script type="math/tex; mode=display">
\textbf{y}[u]=\left\{
\begin{aligned}
+1 & & if \space k||u - c|| \leq R \\
-1 & & otherwise \\
\end{aligned}
\right.\\</script><h5 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数:"></a>损失函数:</h5><p>单分数的损失函数和 <strong>score map</strong> 的平均损失函数定义如下, 其中 <strong>v</strong> 为前向传播得到的分数矩阵 <strong>score map</strong>, <strong>y</strong> 为真实标注的 <strong>score map</strong>.</p>
<script type="math/tex; mode=display">
l(y,v) = log(1 + exp(-yv))\\
L(\textbf y,\textbf v) = \frac{1}{|D|} \sum_{u\in D} l(\textbf y[u],\textbf v[u])\\</script><h5 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构:"></a>网络结构:</h5><ul>
<li>φ 网络为全卷积网络,用于 <strong>exemplar image</strong> 和 <strong>candidate image</strong> 的特征提取, 图中的两个 φ 网络共享所有参数.</li>
<li><strong>exemplar image</strong> 经过 φ 网络得到其对应的大小为 $6\times 6\times 128$ 的特征映射.</li>
<li>由于 <strong>search image</strong> 的尺寸大于 <strong>exemplar image</strong> , 为了定位目标在 <strong>search image</strong> 中的位置,理论上需要需要穷举 <strong>search image</strong> 上所有可能的与 <strong>exemplar image</strong> 尺寸相同的候选子图.   而全卷积网络的<strong>计算共享</strong>的特性使得这样的穷举在一次前向传播中就能够实现.</li>
<li>全卷积网络作用在 <strong>search image</strong> 上的结果是得到一个大小为 $22\times 22\times 128$ 的特征映射,在这个特征映射中可以截取得到所有可能的 <strong>candidate iname</strong> 的特征映射.</li>
<li>将两张图片上得到的特征映射作互相关(内积)并作一定处理后得到 <strong>exemplar image</strong> 与 <strong>search image</strong> 上的各候选子图的相似度分数, 以 <strong>score map</strong> 的形式展现, 其中 <strong>score map</strong> 中的各个点的分数在几何上与 <strong>search image</strong> 中相应位置的 <strong>candidate image</strong> 一一对应.</li>
</ul>
<p><img src="/img/siamFCN/pipeline.png" alt=""></p>
<center><i>图2: 孪生网络结构图</i></center>

<p><img src="/img/siamFCN/parameter.png" alt=""></p>
<center><i>图3: 子网络φ超参数 </i></center>



<h5 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程:"></a>训练过程:</h5><p>以一对训练图片为例, 将 <strong>exemplar image</strong> 喂给上图中的 <strong>z</strong>, 将 <strong>search image</strong> 喂给上图中的 <strong>x</strong> , 之后进行前向传播得到 <strong>score map</strong>, 根据训练标注中所定义的作为 ground truth 的分数矩阵计算 <strong>loss</strong> 执行反向传播算法更新全卷积网络 φ 中的参数.</p>
<h5 id="跟踪测试"><a href="#跟踪测试" class="headerlink" title="跟踪测试:"></a>跟踪测试:</h5><ul>
<li><p>利用第一帧中 bounding box 框出的待检测目标,通过与之前在训练集中使用的相同的裁剪填充操作得到<strong>exemplar image</strong>.</p>
</li>
<li><p>以前一帧检测到的目标位置作为中心,通过与之前在训练集中使用的相同的裁剪填充操作得到当前帧的 <strong>search image</strong> 并结合 <strong>exemplar image</strong> 执行前向传播算法得到对应 <strong>score map</strong>.</p>
</li>
<li><p>利用 <strong>score map</strong> 的最大值点相对于 <strong>score map</strong> 中心点的偏移乘以 stride 得到当前帧中目标相对于上一帧中目标的偏移量.</p>
</li>
<li><p>目标尺寸空间的跟踪通过对 <strong>search image</strong> 的不同缩放版本来实现. </p>
</li>
<li><p>考虑到目标移动的连续性, 引入 <strong>cosine window</strong> 来实现对大幅度偏移的惩罚, 目标尺寸的大幅度变化也会受到惩罚.</p>
</li>
</ul>
<h4 id="全卷积网络的特性"><a href="#全卷积网络的特性" class="headerlink" title="全卷积网络的特性:"></a>全卷积网络的特性:</h4><ul>
<li><p>输入大小可变</p>
</li>
<li><p>计算共享</p>
<ul>
<li>如图 4 中, 当输入的大小大于 $16\times 16$ 时, 输出的大小相应变为 $2 \times 2$. 其中输出结果中的蓝色点对应了输入图片中蓝色部分的结果.</li>
<li>还可以看到, 由于网络中池化层的存在, 当 $14 \times 14$ 的 “滑动窗口” 移动 2 个像素时才会产生一个输出点. 这个移动距离就是文中提到的 stride 值, 论文 Overfeat 中将其比喻成 “滑动窗口的” 分辨率.</li>
<li>当然严格的计算共享需要保证网络中没有 padding 的存在.</li>
</ul>
</li>
</ul>
<p><img src="/img/siamFCN/fcn.png" alt=""></p>
<center><i>图4: Overfeat中关于全卷积网络特性的解释</i></center>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://maoyunyao.github.io/2019/05/19/pytorch_save_load_model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.M">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="漫卷云舒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/19/pytorch_save_load_model/" itemprop="url">模型存取</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-19T12:00:00+10:00">
                2019-05-19
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Pytorch/" itemprop="url" rel="index">
                    <span itemprop="name">Pytorch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="SAVING-AND-LOADING-MODELS"><a href="#SAVING-AND-LOADING-MODELS" class="headerlink" title="SAVING AND LOADING MODELS"></a>SAVING AND LOADING MODELS</h2><p>与众多的深度学习框架一样, Pytorch可以对训练好的模型进行存储, 将来需要时可以随时取用而不必花大量时间重新训练网络.</p>
<h4 id="三个核心函数"><a href="#三个核心函数" class="headerlink" title="三个核心函数"></a>三个核心函数</h4><ul>
<li>torch.save</li>
<li>torch.load</li>
<li>torch.nn.Model.load_state_dict</li>
</ul>
<h4 id="state-dict"><a href="#state-dict" class="headerlink" title="state_dict"></a>state_dict</h4><p>在 Pytorch 中, <code>torch.nn.Module</code> 的可学习参数可以由 <code>model.parameters()</code> 访问. <code>state_dict</code> 是一个 Python 的字典对象, 它将模型的层映射到各自的参数 Tensor. </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define model</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TheModelClass</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(TheModelClass, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = x.view(<span class="number">-1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize model</span></span><br><span class="line">model = TheModelClass()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Initialize optimizer</span></span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print model's state_dict</span></span><br><span class="line">print(<span class="string">"Model's state_dict:"</span>)</span><br><span class="line"><span class="keyword">for</span> param_tensor <span class="keyword">in</span> model.state_dict():</span><br><span class="line">    print(param_tensor, <span class="string">"\t"</span>, model.state_dict()[param_tensor].size())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Print optimizer's state_dict</span></span><br><span class="line">print(<span class="string">"Optimizer's state_dict:"</span>)</span><br><span class="line"><span class="keyword">for</span> var_name <span class="keyword">in</span> optimizer.state_dict():</span><br><span class="line">    print(var_name, <span class="string">"\t"</span>, optimizer.state_dict()[var_name])</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">Model&apos;s state_dict:</span><br><span class="line">conv1.weight	torch.Size([6, 3, 5, 5])</span><br><span class="line">conv1.bias		torch.Size([6])</span><br><span class="line">conv2.weight	torch.Size([16, 6, 5, 5])</span><br><span class="line">conv2.bias		torch.Size([16])</span><br><span class="line">fc1.weight		torch.Size([120, 400])</span><br><span class="line">fc1.bias		torch.Size([120])</span><br><span class="line">fc2.weight		torch.Size([84, 120])</span><br><span class="line">fc2.bias		torch.Size([84])</span><br><span class="line">fc3.weight		torch.Size([10, 84])</span><br><span class="line">fc3.bias		torch.Size([10])</span><br><span class="line">Optimizer&apos;s state_dict:</span><br><span class="line">state 	 &#123;&#125;</span><br><span class="line">param_groups 	 [&#123;&apos;lr&apos;: 0.001, &apos;momentum&apos;: 0.9, &apos;dampening&apos;: 0, &apos;weight_decay&apos;: 0, &apos;nesterov&apos;: False, &apos;params&apos;: [140040066551024, 140041977181024, 140041977181096, 140040066553608, 140040066552384, 140040066319272, 140040066319344, 140040066319416, 140040066319488, 140040066319560]&#125;]</span><br></pre></td></tr></table></figure>
<h4 id="state-dict的保存与加载"><a href="#state-dict的保存与加载" class="headerlink" title="state_dict的保存与加载"></a>state_dict的保存与加载</h4><p>注意必须在加载 <code>state_dict</code> 之后调用 <code>model.eval()</code> 来设置模型的 <code>dropout</code> 和 <code>batch normalization</code> 层. 否则会报错.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存</span></span><br><span class="line">torch.save(model.state_dict(), PATH)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载</span></span><br><span class="line">model = TheModelClass(*args, **kwargs)</span><br><span class="line">model.load_state_dict(torch.load(PATH))</span><br><span class="line">model.eval()</span><br></pre></td></tr></table></figure>
<h4 id="整个模型的保存与加载"><a href="#整个模型的保存与加载" class="headerlink" title="整个模型的保存与加载"></a>整个模型的保存与加载</h4><p>缺点是只能保存给定的类和路径的模型, 因为这种保存方法不保存模型的类本身, 相反它保存一个包含模型的类的定义的文件路径, 故而在加载模型之前, 该模型的类必须事先存在定义, 且路径必须与保存时相同.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存</span></span><br><span class="line">torch.save(model, PATH)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载</span></span><br><span class="line"><span class="comment"># Model class must be defined somewhere</span></span><br><span class="line">model = torch.load(PATH)</span><br><span class="line">model.eval()</span><br></pre></td></tr></table></figure>
<p>如果没有在与保存模型时相同的相对路径下, 加载模型时会出现如下的错误</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>model = torch.load(<span class="string">'/home/myy/Desktop/haha.pth'</span>)</span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">  File <span class="string">"/home/myy/.conda/envs/pytorch/lib/python3.7/site-packages/torch/serialization.py"</span>, line <span class="number">387</span>, <span class="keyword">in</span> load</span><br><span class="line">    <span class="keyword">return</span> _load(f, map_location, pickle_module, **pickle_load_args)</span><br><span class="line">  File <span class="string">"/home/myy/.conda/envs/pytorch/lib/python3.7/site-packages/torch/serialization.py"</span>, line <span class="number">574</span>, <span class="keyword">in</span> _load</span><br><span class="line">    result = unpickler.load()</span><br><span class="line">AttributeError: Can<span class="string">'t get attribute '</span>TheModelClass<span class="string">' on &lt;module '</span>__main__<span class="string">' (built-in)&gt;</span></span><br></pre></td></tr></table></figure>
<h4 id="断点的保存与加载"><a href="#断点的保存与加载" class="headerlink" title="断点的保存与加载"></a>断点的保存与加载</h4><p>保存断点以便继续训练或者什么的</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存</span></span><br><span class="line">torch.save(&#123;</span><br><span class="line">            <span class="string">'epoch'</span>: epoch,</span><br><span class="line">            <span class="string">'model_state_dict'</span>: model.state_dict(),</span><br><span class="line">            <span class="string">'optimizer_state_dict'</span>: optimizer.state_dict(),</span><br><span class="line">            <span class="string">'loss'</span>: loss,</span><br><span class="line">            ...</span><br><span class="line">            &#125;, PATH)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载            </span></span><br><span class="line">model = TheModelClass(*args, **kwargs)</span><br><span class="line">optimizer = TheOptimizerClass(*args, **kwargs)</span><br><span class="line"></span><br><span class="line">checkpoint = torch.load(PATH)</span><br><span class="line">model.load_state_dict(checkpoint[<span class="string">'model_state_dict'</span>])</span><br><span class="line">optimizer.load_state_dict(checkpoint[<span class="string">'optimizer_state_dict'</span>])</span><br><span class="line">epoch = checkpoint[<span class="string">'epoch'</span>]</span><br><span class="line">loss = checkpoint[<span class="string">'loss'</span>]</span><br><span class="line"></span><br><span class="line">model.eval()</span><br><span class="line"><span class="comment"># - or -</span></span><br><span class="line">model.train()</span><br></pre></td></tr></table></figure>
<p>参考文献:</p>
<p>[1]Pytorch - Docs</p>
<p>[2]Pytorch - Tutorials: saving and loading modules</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://maoyunyao.github.io/2019/05/17/pytorch_train_with_gpu/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.M">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="漫卷云舒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/17/pytorch_train_with_gpu/" itemprop="url">利用GPU训练</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-17T18:00:00+10:00">
                2019-05-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Pytorch/" itemprop="url" rel="index">
                    <span itemprop="name">Pytorch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="Train-with-GPU"><a href="#Train-with-GPU" class="headerlink" title="Train with GPU"></a>Train with GPU</h2><p>之前我们已经讨论过 Pytorch 对与 CUDA 的良好支持, 那么自然地我们可以使用强悍的 GPU 设备来训练搭建好的神经网络, 以此来达到加速训练的效果. 毕竟炼丹还是需要良好的硬件支持的是吧.</p>
<h4 id="单GPU训练"><a href="#单GPU训练" class="headerlink" title="单GPU训练"></a>单GPU训练</h4><p>使用单个 GPU 训练的方法非常简单, 我们只需要将网络部署到 CUDA 的 GPU 设备上并且将数据也部署到相同的设备上即可. 部署的方式与我们之前讨论过的 Tensor 的部署方法相同.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>device = torch.device(<span class="string">"cuda:0"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>net.to(device)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>inputs, labels = inputs.to(device), labels.to(device)</span><br></pre></td></tr></table></figure>
<p>注意此处 <code>tensor.to(device)</code> 仅仅将原 Tensor 在 GPU 上作一个拷贝并返回拷贝的 Tensor, 并不对原 Tensor 有任何修改.</p>
<h4 id="多GPU训练"><a href="#多GPU训练" class="headerlink" title="多GPU训练"></a>多GPU训练</h4><p>默认情况下 Pytorch 只会使用单个 GPU 进行模型的训练, 你可以使用 <code>DataParallel</code> 来实现多 GPU 的模型计算, 其原型为</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)</span><br></pre></td></tr></table></figure>
<p>参数解释如下:</p>
<ul>
<li><code>module</code>: 需要多 GPU 并行计算的模型</li>
<li><code>device_ids</code>: CUDA 设备的 ID, 默认为全部可用设备</li>
<li><code>output_device</code>: 输出所在设备, 默认为 <code>device_ids[0]</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> torch.cuda.device_count() == <span class="number">3</span>:</span><br><span class="line">  print(<span class="string">"Let's use"</span>, torch.cuda.device_count(), <span class="string">"GPUs!"</span>)</span><br><span class="line">  model = nn.DataParallel(model, device_ids=[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure>
<p>没错就是这么简单, 结束了.</p>
<p>参考文献:</p>
<p>[1]Pytorch - Docs</p>
<p>[2]Pytorch - Tutorials: A 60 Minute Blitz</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://maoyunyao.github.io/2019/05/17/pytorch_nn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.M">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="漫卷云舒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/17/pytorch_nn/" itemprop="url">神经网络搭建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-17T12:00:00+10:00">
                2019-05-17
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Pytorch/" itemprop="url" rel="index">
                    <span itemprop="name">Pytorch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="torch-nn"><a href="#torch-nn" class="headerlink" title="torch.nn"></a>torch.nn</h2><p>我们可以利用 <code>torch.nn</code> 来搭建神经网络, 其中 <code>nn.Mudule</code> 你可以定义一系列网络层以及一个 <code>forward(input)</code> 方法从输入获取神经网络的输出.</p>
<h4 id="神经网络训练流程"><a href="#神经网络训练流程" class="headerlink" title="神经网络训练流程"></a>神经网络训练流程</h4><ul>
<li>定义带有可训练参数 (权重) 的神经网络结构</li>
<li>训练数据输入神经网络前向传播获得输出</li>
<li>利用数据标签和网络输出计算损失函数</li>
<li>执行反向传播算法, 获得损失函数的输出相对于各参数的梯度值</li>
<li>利用梯度值更新网络的权值</li>
</ul>
<h4 id="定义网络"><a href="#定义网络" class="headerlink" title="定义网络"></a>定义网络</h4><p>在模型中只需到定义 <code>forward()</code> 方法, 而 <code>backward()</code> 方法会自动定义. 在 <code>forward()</code> 方法中可以使用任何的对 Tensor 的操作. 下面的代码是 LeNet 的 Pytorch 实现:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        <span class="comment"># 1 input image channel, 6 output channels, 5x5 square convolution</span></span><br><span class="line">        <span class="comment"># kernel</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        <span class="comment"># an affine operation: y = Wx + b</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="comment"># Max pooling over a (2, 2) window</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># If the size is a square you can only specify a single number</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>)</span><br><span class="line">        x = x.view(<span class="number">-1</span>, self.num_flat_features(x))</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">num_flat_features</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        size = x.size()[<span class="number">1</span>:]  <span class="comment"># all dimensions except the batch dimension</span></span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>net = Net()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(net)</span><br><span class="line">Net(</span><br><span class="line">  (conv1): Conv2d(<span class="number">1</span>, <span class="number">6</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (conv2): Conv2d(<span class="number">6</span>, <span class="number">16</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (fc1): Linear(in_features=<span class="number">400</span>, out_features=<span class="number">120</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">  (fc2): Linear(in_features=<span class="number">120</span>, out_features=<span class="number">84</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">  (fc3): Linear(in_features=<span class="number">84</span>, out_features=<span class="number">10</span>, bias=<span class="keyword">True</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p>模型中可以学习的参数可以由 <code>net.parameters()</code> 返回, 参数是一个个的 Tensor, <code>requires_grad</code> 标志位为 True.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>params = list(net.parameters())</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(len(params))</span><br><span class="line"><span class="number">10</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(params[<span class="number">0</span>].size())  <span class="comment"># conv1's .weight</span></span><br><span class="line">torch.Size([<span class="number">6</span>, <span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>])</span><br></pre></td></tr></table></figure>
<h4 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h4><p>我们可以尝试给如上的网络一个随机的输入, 观察他的输出情况. 注意此处的输入 size 为 (1, 1, 32, 32), 这是因为 <code>torch.nn</code> 只支持 <code>mini-batches</code> 的输入. 例如, 对于 <code>nn.Conv2d</code> , 它所要求的输入是一个 4 维的 Tensor, 即: <code>nSamples * nChannels * Height * Width</code>. 故而如果你的输入是单个样本, 可以利用 <code>input.unsqueeze(0)</code> 来添加一个虚拟维度.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>input = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>out = net(input)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(out)</span><br><span class="line">tensor([[<span class="number">-0.1258</span>, <span class="number">-0.0585</span>, <span class="number">-0.0102</span>, <span class="number">-0.0407</span>, <span class="number">-0.0695</span>, <span class="number">-0.0808</span>,  <span class="number">0.0731</span>, <span class="number">-0.1482</span>,</span><br><span class="line">          <span class="number">0.0575</span>, <span class="number">-0.0164</span>]], grad_fn=&lt;AddmmBackward&gt;)</span><br></pre></td></tr></table></figure>
<h4 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h4><p>损失函数使用 <code>(output, target)</code> 对作为输出, 计算出的值用于度量 output 相对于 target 的距离. <code>porch.nn</code> 中定义了许多现成的损失函数. 一个最简单的例子便是均方误差函数 <code>nn.MSELoss</code> .</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">output = net(input)</span><br><span class="line">target = torch.randn(<span class="number">10</span>)		<span class="comment"># a dummy target, for example</span></span><br><span class="line">target = target.view(<span class="number">1</span>, <span class="number">-1</span>)		<span class="comment"># make it the same shape as output</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line"></span><br><span class="line">loss = criterion(output, target)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(loss)</span><br><span class="line">tensor(<span class="number">0.5244</span>, grad_fn=&lt;MseLossBackward&gt;)</span><br></pre></td></tr></table></figure>
<h4 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h4><p>由于多次反向传播的梯度值的累加机制, 我们在进行一次反向传播更新权重之前, 我们需要用 <code>zero_grad()</code> 对所有参数的 <code>grad</code> 清零, 然后对 loss 调用 <code>backward()</code> 方法就可以得到当前损失函数的输出关于各可训练参数的梯度了.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>net.zero_grad()</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(net.conv1.bias.grad)</span><br><span class="line">tensor([<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>print(net.conv1.bias.grad)</span><br><span class="line">tensor([ <span class="number">0.0185</span>,  <span class="number">0.0110</span>,  <span class="number">0.0038</span>,  <span class="number">0.0098</span>, <span class="number">-0.0105</span>, <span class="number">-0.0002</span>])</span><br></pre></td></tr></table></figure>
<h4 id="更新网络权重"><a href="#更新网络权重" class="headerlink" title="更新网络权重"></a>更新网络权重</h4><p>一个最简单的权重更新方法是随机梯度下降(SGD), 他的策略是 <code>weight = weight - learning_rate * gradient</code> , 我们可以简单实现如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> net.parameters():</span><br><span class="line">    f.data.sub_(f.grad.data * learning_rate)</span><br></pre></td></tr></table></figure>
<p>不过, 作为一个成熟的深度学习框架, Pytorch 应该学会自己更新权重, 故而 <code>torch.optim</code> 实现了许多权重更新的算法供我们使用, 而且使用方法非常简单:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># create your optimizer</span></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># in your training loop:</span></span><br><span class="line">optimizer.zero_grad()   <span class="comment"># zero the gradient buffers</span></span><br><span class="line"></span><br><span class="line">output = net(input)</span><br><span class="line">loss = criterion(output, target)</span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line">optimizer.step()    	<span class="comment"># Does the update</span></span><br></pre></td></tr></table></figure>
<p>参考文献:</p>
<p>[1]Pytorch - Docs</p>
<p>[2]Pytorch - Tutorials: A 60 Minute Blitz</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://maoyunyao.github.io/2019/05/15/pytorch_tensor_create/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Mr.M">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="漫卷云舒">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/05/15/pytorch_tensor_create/" itemprop="url">张量的创建</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-05-15T12:00:00+10:00">
                2019-05-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Pytorch/" itemprop="url" rel="index">
                    <span itemprop="name">Pytorch</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="torch-Tensor"><a href="#torch-Tensor" class="headerlink" title="torch.Tensor"></a>torch.Tensor</h2><p>Tensor 是 Pytorch 的数据结构, 非常类似于 Numpy 里的 ndarray. 是一种包含单一数据类型的多维张量. 其上定义了诸多的操作. 如我们讨论过的自动求导机制等.</p>
<h4 id="张量的创建"><a href="#张量的创建" class="headerlink" title="张量的创建"></a>张量的创建</h4><p><strong>torch.tensor()</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.tensor(data,dtype=<span class="keyword">None</span>,device=<span class="keyword">None</span>,requires_grad=<span class="keyword">False</span>,pin_memory=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<p>利用上述函数创建 Tensor 时, 它总是拷贝 data 内的数据然后利用这些数据结合相应参数构造一个新的叶结点变量, 故而 <code>torch.tensor(x)</code> 与 <code>x.clone().detach()</code> 等价, 而 <code>torch.tensor(x,requires_grad=True)</code> 则与 <code>x.clone().detach().rquires_grad_(True)</code> 等价.</p>
<p>如果想要避免上述的拷贝-创建机制, 请不要使用这个函数 :-). 而如果你想得到一个与原变量共享内存的新 Tensor, 那么可以使用 <code>torch.Tensor.detach()</code> 或者 <code>torch.as_tensor()</code> 等方法. 前者可以从原来的 Tensor 创造一个 <code>requires_grad</code> 标志位为 False 且不在原 Tensor 计算图中的 Tensor, 两者共享内存. 而后者可从 Numpy 的一个 ndarray 创造 Tensor , 两者共享内存.</p>
<p>如果你想修改原 Tensor 的性质, 可以使用 <code>torch.Tensor.requires_grad_()</code> 或者 <code>torch.Tensor.detach_()</code>. 前者使 Tensor 的 <code>requires_grad</code> 标志位为真, 自动求导机制开始记录操作.后者与其不含下划线的版本不同之处在于它修改原 Tensor 的性质, 即将原 Tensor 从计算图中剥离并且置 <code>requires_grad</code> 为 False. </p>
<p>示例代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = [<span class="number">1.</span>, <span class="number">1.</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = [<span class="number">2.</span>, <span class="number">2.</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.tensor(a, requires_grad = <span class="keyword">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = torch.tensor(a, requires_grad = <span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">0</span>] = <span class="number">-1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([<span class="number">-1.</span>,  <span class="number">1.</span>], grad_fn=&lt;CopySlices&gt;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">[<span class="number">1.0</span>, <span class="number">1.0</span>]</span><br><span class="line"><span class="comment"># 可见 x 与 a 并不共享内存</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>x_ = x.detach()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([<span class="number">-1.</span>,  <span class="number">1.</span>], grad_fn=&lt;CopySlices&gt;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x_</span><br><span class="line">tensor([<span class="number">-1.</span>,  <span class="number">1.</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x[<span class="number">0</span>] = <span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>], grad_fn=&lt;CopySlices&gt;)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x_</span><br><span class="line">tensor([<span class="number">1.</span>, <span class="number">1.</span>])</span><br><span class="line"><span class="comment"># 可见 x 与 x_ 共享内存</span></span><br></pre></td></tr></table></figure>
<p><strong>torch.as_tensor()</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.as_tensor(data, dtype=<span class="keyword">None</span>, device=<span class="keyword">None</span>)</span><br></pre></td></tr></table></figure>
<p>如果 data 是一个 Tensor 且数据类型与设备参数相同, 则直接共享该 Tensor 的内存给新 Tensor. 如果 data 是一个 Tensor 而数据类型或设备不符, 则会新创建一个 Tensor, 新 Tensor 保持原 Tensor 的计算图和 <code>requires_grad</code> 标志位. 如果 data 是一个数据类型相同的 ndarray , 且参数中指定的设备为 CPU, 则新 Tensor 与该 ndarray 共享内存.</p>
<p>示例代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = numpy.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = torch.as_tensor(a)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">0</span>] = <span class="number">-1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([<span class="number">-1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = numpy.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t = torch.as_tensor(a, device=torch.device(<span class="string">'cuda'</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>t[<span class="number">0</span>] = <span class="number">-1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a</span><br><span class="line">array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure>
<h4 id="其他一些创建方法"><a href="#其他一些创建方法" class="headerlink" title="其他一些创建方法"></a>其他一些创建方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.ones(<span class="number">5</span>, <span class="number">6</span>)</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>q = torch.zeros(<span class="number">5</span>, <span class="number">6</span>)</span><br><span class="line">tensor([[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>],</span><br><span class="line">        [<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]])</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.ones_like(q)</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line">......</span><br></pre></td></tr></table></figure>
<p>参考文献:</p>
<p>[1]Pytorch - Docs</p>
<p>[2]Pytorch - Tutorials: A 60 Minute Blitz</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="Mr.M" />
            
              <p class="site-author-name" itemprop="name">Mr.M</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">18</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="mailto:myy2016@mail.ustc.edu.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Mr.M</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
